\chapter{Modelo y propuesta de Investigación}

\section{Modelo de Investigación de la estimación de parámetros morfológicos en rocas sedimentarias usando Fourier Elíptico y redes neuronales}

En la Figura~\ref{fig:fig14} se describen las etapas de investigación, para después ser detalladas.

\begin{itemize}
	\item La primera etapa consiste en conseguir 1123 imágenes de todas las clases de esfericidad y redondez para poder entrenar de manera equitativa la red, y después probar con las imágenes de Krumbein (\cite{Krumbein1941}) y verificar los resultados.
	\item La segunda etapa se obtiene el valor de redondez y esfericidad de cada una de las imágenes de entrenamiento con los métodos propuestos.
	\item La tercera etapa se saca el valor de las constantes de los primeros 40 armónicos de la serie de Fourier Elíptico de cada una de las imágenes de entrenamiento, aparte, relacionar estos armónicos con su valor de esfericidad y redondez.
	\begin{figure}[hbtp]
		\centering 
		\includegraphics[angle=90,origin=c,scale=.55]{figuras/diagramaFlujoTrabajo.png}
		\caption{Modelo metodológico de la estimación de parámetros morfológicos en rocas sedimentarias usando Fourier Elíptico y redes neuronales}
		\label{fig:fig14}
	\end{figure}
	\item La cuarta etapa consiste entrenar las 2 redes neuronales, la que va a clasificar la esfericidad, y la que va a clasificar la redondez, con los valores de entrada que será los armónicos de Fourier Elíptico y su respectiva salida.
	\item Una vez entrenada cada red, obtener los armónicos de Fourier Elíptico de las imágenes de prueba.
	\item La última etapa es clasificar las imágenes de prueba y observar los resultados.
\end{itemize}

\section{Fourier Elíptico}

Los coeficientes de Fourier han sido muy utilizados para caracterizar contornos cerrados. Fourier Elíptico es una manera simple de obtener los coeficientes de Fourier del código de cadena de un contorno cerrado. Los coeficientes resultantes son invariantes a la escala, rotación y traslación.

El código de cadena es el primer paso en Fourier Elíptico, fue descrito inicialmente por Freeman\cite{freeman1974computer}, aproximando un contorno cerrado por una secuencia en partes con 8 posibles valores. El código de un contorno es la cadena \(V\) de longitud \(K\):
\begin{equation}
	V = a_1a_2a_3...a_K,
\end{equation}
donde cada unión \(a_i\) es un entero del 0 al 7 orientado en la dirección \((\frac{\pi}{r})a_i\) \cite{Kuhl1982}.
%Aclarar este parrafo
En la Figura~\ref{fig:fig15} se puede observar como un contorno cerrado separado en píxeles, se puede obtener el código de cadena, trazando una trayectoria desde un punto inicial, hasta volver a llegar a ese mismo punto, pasando por todo el contorno. El código de cadena de la Figura~\ref{fig:fig15}a iniciando de el extremo superior izquierdo es:
\begin{equation}
	V = 0005676644422123
\end{equation}
\begin{figure}[H]
	\centering 
	\includegraphics[scale=1]{codigoCadena.png}
	\caption{Representación gráfica del código de cadena de un contorno cerrado \cite{Kuhl1982}}
	\label{fig:fig15}
\end{figure}

Debido a que el cambio en el código de cadena esa constante y no varía, los coeficientes pueden ser encontrados más fácilmente. Por lo que los coeficientes de la componente \(x\) son:
\begin{equation}
	a_n = \frac{T}{2n^2\pi^2}\sum_{p = 1}^{K}\frac{\Delta x_p}{\Delta t_p}[\cos{\frac{2n\pi t_p}{T}} - \cos{\frac{2n\pi t_{p-1}}{T}}]
\end{equation}
\begin{equation}
	b_n = \frac{T}{2n^2\pi^2}\sum_{p = 1}^{K}\frac{\Delta x_p}{\Delta t_p}[\sin{\frac{2n\pi t_p}{T}} - \sin{\frac{2n\pi t_{p-1}}{T}}]
\end{equation}
donde, la K es el número de píxeles del contorno, \(T\) el período fundamental, \(\Delta x_p\) el cambio en el eje de las x, \(\Delta t_p\) el cambio en el tiempo.

Con eso obtendríamos los coeficientes de la componente \(x\), pero como una imagen es una señal en dos dimensiones necesitamos también obtener los coeficientes de la componente \(y\).
\begin{equation}
	c_n = \frac{T}{2n^2\pi^2}\sum_{p = 1}^{K}\frac{\Delta y_p}{\Delta t_p}[\cos{\frac{2n\pi t_p}{T}} - \cos{\frac{2n\pi t_{p-1}}{T}}]
\end{equation}
\begin{equation}
	d_n = \frac{T}{2n^2\pi^2}\sum_{p = 1}^{K}\frac{\Delta y_p}{\Delta t_p}[\sin{\frac{2n\pi t_p}{T}} - \sin{\frac{2n\pi t_{p-1}}{T}}]
\end{equation}
Con eso ya se tendría los coeficientes necesarios, debido a que el cambio de la \(x\) no siempre sera igual al cambio en las \(y\), Fourier Elíptico generaría elipses en vez de círculos como el método tradicional.

Para que este método obtenga la invarianza a la escala, rotación y traslación, es necesario aplicar una normalización y ajustar los ángulos en los que va a iniciar cada elipse, para que independientemente la escala, rotación y traslación que tenga el contorno cerrado, siempre de el mismo resultado.
\begin{equation}
	E_p = ((A_0-x_p)^2 + (C_0-y_p)^2)^\frac{1}{2}
\end{equation}
donde \(A_0\) y \(C_0\) son el promedio de la energía de las componentes \(x\) y \(y\) respectivamente. Para obtener el ángulo de rotación inicial \(\theta_p\) a el índice \(p\):
\begin{equation}
	\theta_p = \frac{2\pi t_p}{T}, 0<\theta_p\le2\pi
\end{equation}
y para obtener el ángulo de rotación espacial \(\psi_p\)
\begin{equation}
	\psi_p=\arctan[\frac{y_p-C_0}{x_p-A_0}], 0\le\psi_p<2\pi
\end{equation}
Al iniciar el cálculo de los coeficientes, se tendría que obtener \(E_1\), \(\theta_1\) y \(\psi_1\) para influir en los siguiente coeficientes a que se reajusten de acuerdo a estos ángulos iniciales, y dividirlo entre \(E_0\) para mantener la invarianza a la escala, por lo que la obtención de los nuevos coeficientes sería:
\begin{equation}
	\begin{bmatrix}
	1a^{**}_n & 1b^{**}_n\\
	1c^{**}_n & 1d^{**}_n
	\end{bmatrix} =
	\begin{bmatrix}
	\cos{\psi_1} & \sin{\psi_1}\\
	-\sin{\psi_1} & \cos{\psi_1}
	\end{bmatrix}
	\begin{bmatrix}
	a_n & b_n\\
	c_n & d_n
	\end{bmatrix}
	\begin{bmatrix}
	\cos{n\theta_1} & -\sin{n\theta_1}\\
	\sin{n\theta_1} & \cos{n\theta_1}
	\end{bmatrix}
\end{equation}
\begin{equation}
	\begin{bmatrix}
	2a^{**}_n & 2b^{**}_n\\
	2c^{**}_n & 2d^{**}_n
	\end{bmatrix} =
	(-1)^{n+1}
	\begin{bmatrix}
	1a^{**}_n & 1b^{**}_n\\
	1c^{**}_n & 1d^{**}_n
	\end{bmatrix}
\end{equation}
El resultado de la ecuación 3.11 nos daría los coeficientes \(a,b,c,d\) para el \(n\) armónico que se está calculando. Siendo invariante a la escala, rotación y traslación. Para más información, consultar \cite{Kuhl1982}.
\section{Algoritmo para estimar la redondez}

Debido a que el término de redondez es de segundo orden, por lo tanto más complejo, se propuso utilizar el algoritmo de Zheng \cite{Zheng2016}. Basado en la propuesta de Wadell \cite{Wadell1935} consiste en identificar círculos en cada una de las esquinas y que se ajusten a ellas. Resulta complejo debido a que el número de esquinas varía de partícula a partícula.

 Iniciamos obteniendo el radio del máximo círculo circunscrito de la partícula: el paso a) es tener nuestra imagen de la partícula en binario, en el paso b) es transformar nuestra imagen en un mapa de distancias euclidianas, una matriz que nos indica que tan retirado esta un píxel de un contorno cerrado, entre más distancia alla, más valor va a tener; y por último, en el paso c), agarramos el píxel más retirado del contorno de la partícula como el centro del círculo, y su valor en la matriz del paso b) será el radio. En la Figura~\ref{fig:circunFlujo} se observan estos pasos antes mencionados.

\begin{figure}[H]
	\centering 
	\includegraphics[scale=.42]{figuras/fig3_1.png}
	\caption{Flujo de trabajo para obtener el mayor círculo circunscrito.}
	\label{fig:circunFlujo}
\end{figure}

Al haber obtenido el mayor círculo circunscrito, ahora se tiene que trazar un círculo que se ajuste a cada una de las esquinas, pero antes de eso, se tiene que suavizar el contorno de la partícula, para evitar que la información de la rugosidad afecte con el ajuste de los círculos. En el artículo de Zheng \cite{Zheng2016} usan la regresión \textit{LOESS} y \textit{k-folds} para suavizar la partícula, pero nosotros decidimos usar Fourier Elíptico solo tomando en cuenta los primeros 30 armónicos de la serie por la facilidad que resulta quitar la información de la rugosidad.

\begin{figure}[H]
	\centering 
	\includegraphics[scale=.42]{figuras/fig3_2.png}
	\caption{Resultado del suavizado de la partícula utilizando Fourier Elíptico.}
	\label{fig:suavFourier}
\end{figure}

En la figura~\ref{fig:suavFourier}, se observa el suavizado generado por Fourier Elíptico. Para poder identificar las esquinas de la partícula, se necesita analizar todo el contorno de la partícula iniciando desde cualquier punto e ir analizando que la sucesión de puntos tenga un valor de curvatura positiva, de esta manera se puede discriminar cuando esa curvatura se encuentra por fuera de la partícula y solo dejando las que están por dentro. Para formar los círculos, se utiliza una distancia máxima la cual regula que tan retirados deben de estar los píxeles del contorno para ser considerados como una sola esquina para después ajustar un círculo a todos esos puntos.

\begin{figure}[H]
	\centering 
	\includegraphics[scale=.42]{figuras/fig3_3.png}
	\caption{Flujo para aproximar las esquinas con círculos.}
	\label{fig:flujoCirculos}
\end{figure}

En la Figura~\ref{fig:circunFlujo} se muestra como obtener los círculos. (a) tenemos el contorno de la partícula; (b) remarcamos las posibles partes del contorno que podrían ser esquinas utilizando geometría computacional; (c) en base a discriminar las regiones por medio de la curvatura y longitud que poseén, se seleccionan las esquinas y se aproxima un círculo para representarlas.
\begin{equation}
	\label{eqn:roundness}
	\frac{\sum{\frac{r}{R}}}{N} = \text{Grado de redondez}
\end{equation}
Una vez obtenido lo anterior, se pasa a calcular el grado de redondez, la fórmula~\ref{eqn:roundness}. La parte del numerador es el promedio de los radios de todos los círculos de las esquinas entre el radio del círculo circunscrito más grande en la partícula, obteniendo un valor que esta entre 0 y 1, como se describe en el artículo de Zheng y Hryciw \cite{Zheng2016}.

Solo existe un pequeño problema con este algoritmo, se tiene que ajustar ciertos problemas para que pueda funcionar de manera correcta con todas las partículas ya que no es invariante a la escala, lo que ocasionaría en que se obtenga un grado de redondez diferente al real dependiendo de la escala de cada partícula, solo hay que tener mucho cuidado con estos parámetros.

\section{Redes neuronales}

Una red neuronal artificial es un tipo de algoritmo de \textit{Machine Learning} el cual trata de simular el comportamiento del cerebro, al cual le llega una entrada, por medio de neuronas que se activan o no, se obtiene un resultado.

\begin{figure}[H]
	\centering 
	\includegraphics[scale=.8]{figuras/redNeuronal.jpg}
	\caption{Estructura de una neurona artificial análogo a una biológica.}
	\label{fig:estructuraNeurona}
\end{figure}

La neurona es la unidad básica, posee dos tareas las cuales son combinar entrada y producir la señal de activación, siendo un nodo en un grafo dirigido (Red neuronal artificial). La conexión entre 2 neuronas es conocida como la sinapsis y su fuerza esta determinada por el estímulo externo. 

\begin{figure}[H]
	\centering 
	\includegraphics[scale=.5]{figuras/ANN.png}
	\caption{Arquitectura de una red neuronal artificial.}
	\label{fig:arqRedNeuronal}
\end{figure}

Las conexiones o aristas están regidas por pesos (\(w_{ij}\)), esos pesos se mezclan con las entradas para producir el "estímulo", todos los estímulos de entrada hacia una neurona se combinan para después ingresarlas a la función de activación (\(f()\)) que determinará la salida hacia la siguiente neurona. En la Figura~\ref{fig:estructuraNeurona} se puede observar los elementos relacionados a una neurona de una red neuronal artificial. 

En la Figura~\ref{fig:arqRedNeuronal} se observa la arquitectura de una red neuronal con su capa de entrada con 4 neuronas, 4 capas ocultas con 7 neuronas cada una, y su capa de salida con 4 neuronas.

\subsection{Funciones de Activación}

Las funciones de activación tienen como objetivo el acotar los valores de salida de una neurona a un cierto rango de valores. La selección de las funciones de activación dependerá del problema con el cual se este manejando. Existen funciones lineales y no lineales, solamente que las lineales tienen un uso exclusivo unicamente cuando el problema se trate de regresión, y solamente en la capa de salida.

\begin{figure}[H]
	\centering 
	\includegraphics[scale=.6]{figuras/Sigmoid.png}
	\caption{Función de activación Sigmoide.}
	\label{fig:sigmoid}
\end{figure}
\useshortskip
\begin{equation}
	\label{eqn:sigmoid}
	g(x)= \sigma(x)= \frac{1}{1+e^{-x}} \;\;\;\;\;\;\;\; g'(x)= \sigma(x)(1-\sigma(x))
\end{equation} 
La primer función de activación que surgió fue la Sigmoide, representada en la Figura ~\ref{fig:sigmoid} y expresada por la función \(g(x)\) y su derivada \(g'(x)\) ~\ref{eqn:sigmoid}. Utilizada principalmente para clasificar un conjunto de datos en 2 clases. La utilización de ella se ha visto mermada porque presenta 2 grandes problemas a la hora de utilizarla como función de activación en las capas ocultas:

\begin{itemize}
	\item Asimetría positiva
	\item Desvanecimiento del gradiente
	\item Utilización de la función exponencial es costoso.
\end{itemize}

La asimetría positiva provoca que el gradiente se vuelva muy ineficiente a la hora de buscar el mínimo, debido a que solo puede tomar direcciones totalmente negativas o totalmente positivas,haciendo como una especie de zigzag hasta encontrar el punto mínimo. El desvanecimiento del gradiente se puede observar en la Figura ~\ref{fig:sigmoid}, ya que, a medida que los valores de x van incrementando, el valor de la derivada va teniendo a 0, provocando que no haya una retroalimentación a la hora de retropropagar hacia atrás, terminando en que se la red neuronal deje de aprender ya que sus pesos no se van a ir actualizando.

La función se puede seguir usando en la capa de salida pero solo sí el problema lo requiere. Las funciones posteriores trataron de eliminar estos problemas antes mencionados

\begin{figure}[H]
	\centering 
	\includegraphics[scale=.6]{figuras/TanH.png}
	\caption{Función de activación Tangente Hiperbólico.}
	\label{fig:tanh}
\end{figure}
\useshortskip
\begin{equation}
	\label{eqn:tanh}
	g(x)= \tanh{x}=\frac{e^x - e^{-x}}{e^x + e^{-x}} \;\;\;\;\;\;\;\; g'(x)= 1 - \tanh^2{x}=\frac{4}{(e^x+e^{-x})^2}
\end{equation} 
La siguiente función que surgió fue la Tangente Hiperbólico (TanH), introducida por LeCun en 1991, representada en la Figura~\ref{fig:tanh}, expresada junto con su derivada en la Ecuación~\ref{eqn:tanh}. Al observar los problemas que presentaba la función Sigmoide, lo que se trataba de encontrar con la función TanH era eliminarlos, sin embargo, solo fue capaz de solucionar el problema de la asimetría positiva centrando los datos de -1 a 1, para que el descenso del gradiente fuera más eficiente. Sigue presentando los problemas de desvanecimiento del gradiente conforme los valores de \(x\) son más grandes, y sigue existiendo el alto costo por usar la función exponencial.

\begin{figure}[H]
	\centering 
	\includegraphics[scale=.6]{figuras/ReLU.png}
	\caption{Función de activación ReLU (Unidad Lineal Rectificada).}
	\label{fig:relu}
\end{figure}
\useshortskip
\begin{equation}
	\label{eqn:relu}
	g(x)= max(0,x) \;\;\;\;\;\;\;\; g'(x)= u(x)
\end{equation} 
La función ReLU o Unidad Lineal Rectificada fue introducida por Vinod Nair en 2010 \cite{nair2010rectified}, representada en la Figura~\ref{fig:relu}, expresada junto a su derivada en la Ecuación~\ref{eqn:relu}, la función \(u(x)\) es el escalón unitario. Nació para atacar el problema del desvanecimiento del gradiente, pero sigue conservando, en una menor magnitud, que las otras 2 funciones. Sigue poseyendo el problema de la asimetría positiva por no centrar los datos, y se corre el riesgo de que partes de la red neuronal se desconecten si la función empieza a enviar puros ceros, pero tiene la ventaja de que tiene un costo bastante bajo.

Fue muy popular años más tarde de su nacimiento, pero por los problemas que siguieron existiendo se trató de buscar una variante la cual controlara o eliminara por completo los problemas, son las siguientes 2 funciones de activación.

\begin{figure}[H]
	\centering 
	\includegraphics[scale=.6]{figuras/PReLU.png}
	\caption{Función de activación PReLU (Unidad Lineal Rectificada Parametrizada).}
	\label{fig:prelu}
\end{figure}
\useshortskip
\begin{equation}
	\label{eqn:prelu}
	g(x)= max(\alpha x,x) \;\;\;\;\;\;\;\; g'(x) = \alpha + (1-\alpha)u(x)
\end{equation} 
La función PReLU o Unidad Lineal Rectificada Parametrizada fue introducida por Xiangyu Zhang en el año 2015 \cite{he2015delving}, representada en la Figura~\ref{fig:prelu}, expresada junto a su derivada en la Ecuación~\ref{eqn:prelu}. El parámetro \(\alpha\) es un coeficiente que va irse adaptando y aprendiendo a lo largo del proceso de aprendizaje de la red neuronal, promoviendo la rapidez del aprendizaje. Ataca principalmente el desvanecimiento del gradiente, ya que la derivada no sería cero, y estaría habiendo retroalimentación en la red, evitando que se desconecten partes de la misma, como a su vez logra reducir la asimetría positiva. La función Leaky ReLU es un caso particular de está función en la cual se igual \(\alpha\) a una constante.

\begin{figure}[H]
	\centering 
	\includegraphics[scale=.6]{figuras/ELU.png}
	\caption{Función de activación ELU (Unidad Lineal Exponencial).}
	\label{fig:elu}
\end{figure}
\useshortskip
\begin{equation}
	\label{eqn:elu}
	g(x)=
	\begin{cases}
	x & x\ge 0\\
	e^x-1 & x<0
	\end{cases}
	\;\;\;\;\;\;\;\;
	g'(x)=
	\begin{cases}
	1 & x\ge 0\\
	e^x & x<0
	\end{cases}
\end{equation} 
Por último, se tiene la función ELU o Unidad Lineal Exponencial introducido por Djork-Arne Clevert en 2016 \cite{clevert2015fast}. Una gran mejora a comparación de ReLU, ya que no sufre del problema de que se desconecten partes de la red, ataca de mejor manera la asimetría positiva, mejora la velocidad de aprendizaje de la red neuronal, a pesar de utilizar la función exponencial y aumentar el tiempo de procesamiento, es un buen trato por obtener una buena función de activación.

Para este trabajo, se tomaron en cuenta las funciones PReLU y ELU por ser las más confiables y las que poseen menos problemas, solamente para las capas ocultas. La capa de salida se tomó en cuenta una función lineal de la esfericidad, para verlo como un problema de regresión; y para la redondez, se tomó en cuenta la función Softmax para verlo como un problema de clasificación. 

La función Softmax transforma la salida en probabilidades de semejanza que puede tener el sujeto en cuestión a cada una de las clases que se tienen, de esta manera, la clase con mayor probabilidad, sería la clase definida para ese sujeto.



Los pesos de cada conexión entre neuronas se actualiza al final de cada época, ese valor esta definido por una función optimizadora que se necesita una velocidad de aprendizaje o \textit{"learning rate"} y una función de error que calcula que tan errónea fue la salida de la red neuronal con respecto al valor original, si la velocidad de aprendizaje es muy alta, nunca va a encontrar el punto mínimo debido a que siempre se lo va a pasar y regresar una y otra vez, si el valor es muy pequeño, la función tardaría demasiado en llegar y quizás nunca converja.

Actualmente existen funciones las cuales se les puede asignar un valor de aprendizaje alto pero a su vez asignar un valor de caída del aprendizaje, haciendo que en las época iniciales sea muy rápido pero su velocidad vaya bajando gradualmente para ayudar en la convergencia. Tal es el caso de la función RMSprop, que se describen en las siguientes ecuaciones: %~\ref{eqn:rmsprop} están sus ecuaciones.
\begin{equation}
	V_{dw}=\beta\cdot V_{dw}+(1-\beta)\cdot dw^2 
\end{equation}
\begin{equation}
	V_{db}=\beta\cdot V_{dw}+(1-\beta)\cdot db^2
\end{equation}
\begin{equation}
	W = W - \alpha\cdot \frac{dw}{\sqrt{V_{dw}}+\epsilon} 
\end{equation}
\begin{equation}
	b = b - \alpha\cdot \frac{db}{\sqrt{V_{db}}+\epsilon}
\end{equation}
La función de error ayuda a la de optimización a medir el error que hay entre el resultado obtenido y el real, de tal manera que se sepa que tanto se tienen que actualizar los pesos para ir reduciendo el error lo más posible.

Una época esta definida por la ejecución de cierto flujo de pasos, inicia al ingresar el primer registro de los datos, después actualizar los pesos en base al error, así hasta acabar con cada uno de los registros, esa es la duración de una época.



%\begin{equation}
%\begin{split}
%\label{eqn:rmsprop}
%V_{dw}=\beta\cdot V_{dw}+(1-\beta)\cdot dw^2 \\
%%V_{db}=\beta\cdot V_{dw}+(1-\beta)\cdot db^2 \\
%W = W - \alpha\cdot \frac{dw}{\sqrt{V_{dw}}+\epsilon} \\
%b = b - \alpha\cdot \frac{db}{\sqrt{V_{db}}+\epsilon}
%\end{split}
%\end{equation}